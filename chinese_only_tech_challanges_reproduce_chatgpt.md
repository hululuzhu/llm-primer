# 对于“纯复现ChatGPT有多难”的一些思考

最近聊起ChatGPT，常见问题就是“复现ChatGPT有多难“。凑齐巨大人力财力和算力不好估计。但假设资源充足，纯粹技术上复现ChatGPT有什么挑战？我对这个问题做了一些功课，也找朋友咨询了一下，有了一些具体的想法分享，希望大家指正。 结合论文，博文和网上讨论，我个人觉得复现ChatGPT有8步，其中4步有难度。

## TLDR
1. 【比较困难】用海量文字和代码在GPU集群训练GPT3 codex版基础模型。
2. 高质量的专家问答数据“示范”，微调成GPT SFT。
3. 【比较困难】开放模型，了解用户在哪些场景问哪些代表性的问题。
4. 收集问答场景，模型采样产生多种答案让人工排序，以此学习奖励模型（输入问答，输出奖励预测值）。
5. 【非常困难】使用语言模型和奖励模型用强化学习的方式来提高能力。
6. 【比较困难】第三到第五步迭代多次。期待了解更多问题，奖励模型更精确，模型也越来越强。流程上需要引入更好的评价机制。
7. 审核（Moderation API）判断用户问题是否有害。
8. ChatGPT系统发布，问题先审核，通过后让语言模型输出。


## 细节讨论
- 第一步，训练基础模型。OpenAI在2020做了1700亿参数的GPT3。2021百度有了Ernie阿里有了M6。Facebook 2022复现OPT。BigScience实现了bloom。清华发布了GLM。有这么多的经验，虽然数据收集和训练技术上还是很难（参考OPT论文备注），但不算遥不可及。

- 第二步，专家标记问答数据（问答都是人类）给模型“示范”高质量答题规范。这里要确定专家问题的范围有困难。找人的话有很多语言学背景的人符合要求，还有ScaleAI和MTurk这样的平台帮人雇佣。有了这步数据，可以微调模型到GPT的SFT版本，技术上就是第一步的延伸。总体不算难，但对于GPT3从通用模型到问答模型的转变作用巨大。

- 第三步，开放模型让大家用，来了解具体场景有什么问题。这比训练难度小，但也有低延迟的困难。更难的在于鼓励“真的想用的人”来贡献有价值的问题。论文说需要6万多问题（应该还有去重，但论文没有细节）。这步有难度。

- 第四步，人工对当前模型产生的结果排序（随机采样下，同样模型同样输入有不同输出）训练奖励模型。这里需要一个60亿参数的基础模型来训练奖励模型。所以在第一步还需要加上一个小的60亿模型，也就大模型的一个零头。应该没问题。

- 第五步，强化训练（自我博弈提高）这一步我认为非常困难。原因有几点：
  - 1）前面都是监督模型（预训练阶段是自监督）可以理解为“模仿”。输入上文，对于接下来这个字符，监督数据告诉优化器怎么模仿。一个字符一个字符的反馈可以用来优化“模仿”。但到了强化学习，反馈只有大段文字最后的一个打分。比如写一篇命题作文，监督学习下，有个老师一个词一个词和模型谈细节，模型只要去“模仿和纠正”。但到了强化学习，大段的文字模型只得到一个分数，没有“老师”给它讲细节（哪里好，哪里不好，这个难点也叫credit assignment问题）。那怎么提高分数？模型需要自己去“悟”！虽然可以通过算法帮助模型，但难度会高出监督学习很多。
  - 2）如何平衡“更高的分数”和“符合常理的输出”？回到写作文的例子，只追求高分数，模型有可能剑走偏锋写出“赤兔之死”这样的怪文，所以这里是一个约束条件（和本来模型尽可能类似）下的优化（更高的分数），可以用超参数来人工选择如何平衡，或者用拉格朗日松弛技术等数学方法来实现，我认为这些细节需要做研究。
  - 3）训练本身很难，要融合语言模型和奖励模型变成一个系统，同时兼顾大系统多步骤的迭代，架构就很费劲。优化本身可以用OpenAI的PPO（有很多开源），但设计模型奖励/损失函数和使用PPO一般都有很多超参要调。因为基础模型不一样，论文中的超参数大概率不会直接起效，所以这里还需要非常多的尝试（参考DeepMind Sparrow论文，轻飘飘一句A2C比V-MPO好，背后就是无数心血）
  - 4）奖励模型不完美，甚至带有偏见，这样强化学习就变成了让模型去强调这个偏见！这里就需要一个更好的评价机制和奖励模型。
  - 总之强化学习的难点非常多，这一步非常困难，不是堆人力算力就可以加速。

- 第六步，对之前3步迭代，算是一个流程整合。我觉得还应该需要引入更好的评价机制，这样可以理解每一次的迭代到底有没有提高模型能力，有没有过拟合？这里除了使用一些已有数据集，标记团队应该也要标记更多数据。

- 第七步，审核模型来判断用户的问题是否“有毒”。按照论文，这是语言模型之外的一个单独模型。在假设有毒数据可以收集的基础上就是一个二元鉴别器。所以不算难。

- 第八步，上线复现版，需要在第三步上面实现一个更好的前台API和后台。感觉这一步在前面基础上问题不大。


## 简单总结
综上，假设资源充足，我觉得复现ChatGPT的技术挑战合并起来还有两点：
- 一是高质量训练和反馈数据，了解未来的用户真的关心哪些问题可以有目标去优化，加上如何设计高效的评价反馈系统？
- 二是强化学习的训练本身，要成功的使用强化学习让巨型语言模型能力提升非常难。
