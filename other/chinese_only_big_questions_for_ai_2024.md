因为做AI普及的关系，我经常有机会和学生家长或老师讨论相关的话题，有时候被问到AI的热点，我发现很难回答。

我觉得与其猜测未来几年AI的具体热点，或许可以把一些AI相关的问题归纳一下，这样能方便孩子们自己思考未来要去解决的AI相关问题？

虽然我能力有限，但我还是希望抛砖引玉开始写一点，或许加上朋友们的批评指教，能给学生和家长们一点有用的信息。

我个人认为的AI相关的几大问题：

- AI的超级对齐，如果使未来的超强AI符合我们大众对于AI造福人类的预期。
  - AI的超级对齐(super alignment)是很有意思，未来的超强AI一定不能失控！如何做到这一点，除了技术上的思考，也相当程度上有哲学的影子，现在根据公开资料，真心投入这个领域的应该只有OpenAI一家，号称用了整个公司20%以上的算力去探索这个问题。去年末他们的“weak to strong generalization”的研究就非常有意思，我很期待未来OpenAI和其他大公司有更多相关的研究。我也很期待现在各种开源模型的加持下，学术界也有更多关于这方面的参与。

- AI的具体超能力，如何能训练和激发未来的AI能辅助甚至替代科学家的工作。
  - AI的具体的超能力是现在很多AI科研的热点，大家应该都听说AI下棋打游戏做数学，预测蛋白质，这里面OpenAI，DeepMind，FAIR等都有相关的研究。在现在的AI能力下(加上AI与外部世界的交互)继续提升，未来如果AI能实现科研的猜想，实验/论证，归纳，提升的闭环，那AI就一定程度上具备了科学家的能力，我们在很多领域比如材料生物医药或许就能加速诺贝尔级别研究的发现。OpenAI的Sam Altman在和比尔盖茨的谈话里提到说现在的GPT你问它一个很难得问题(比如数学猜想)，你问它一万次可能其中有一次非常棒，但问题是OpenAI暂时还不知道怎么稳定的了解哪一次的效果最佳。DeepMind用来做AlphaCode还有FunSearch这样的用推理成本加验证器的方法很相关。或许降低成本和延迟，提升自动验证器能力，提升交互能力，就能接近科研AI的愿景。

- AI的理论深入，未来有没有可能诞生更精确的AI理论指导实践。
  - 现在很多时候我们说的AI都是深度神经网络架构为主的大模型。这里有一些理论，比如神经元，激活函数，normalization，regularization，优化算法，scaling law，Transformer的self attention等等，但这里的理论不是那种如经典力学一样的精确理论。有些“理论”比如RLHF为什么有用，DPO为什么可以达到类似RLHF的效果，他们都有数学公式，但还远不是物理公式那样的精确，虽然他们的实用效果已经让很多人受益匪浅。这些不精确的理论支撑下的AI，也带来不确定性，这种不确定性在我们需要完全掌控AI的能力时候会产生问题，比如OpenAI还未解释为何ChatGPT在11月底突然变懒这个问题。

- AI的应用，如何能将AI的能力拓展或者深入到每一个细分领域，并降低成本。
  - AI的应用最深入我们的生活，我们绝大多数做AI相关从业人员比如我，都是在某一个细分领域需要反复思考和实验如何提升AI的有用程度。而为了具体提升AI的具体能力，我们需要去深入思考这个领域的“有用指标”，理解现在AI基础模型的能力和局限，收集高质量的数据标本，用合适的方式去训练AI符合领域的有用指标的提升，和真实环境(用户交互，工业生产)交互下的反馈到指标到数据到再提升的闭环。而我同时也认为AI如此的有用，它可以在各个学科发挥比数字化和统计更有用的作用。从这一点来看，其实大学生选什么专业可能不那么重要，做到一个领域的专家，加上了解AI的能力和局限，用AI作为助手，应该是未来几年的主流方向。另外，AI作为应用是一个除了模型以外的系统，所以我们需要工程师来实现模型训练推理等等所有相关的工程问题。

- AI的微观透视，如何探索AI(特别是基于神经网络)的内部结构和运算机理。
  - 我觉得AI的微观透视是和脑科学去终极探索人脑如何运作是紧密相关的。现在深度学习中很多思想(神经元，激活函数)都来自于脑科学。但现在的大模型如此之大，又考虑多模态的输入输出，这个难度可能已经超过了脑科学去探索人脑皮层或者某一区域功能的研究。到底是依靠脑科学或者其他实验科学的进步来辅助AI的解释性研究，还是神经网络AI本身的研究能帮助我们未来更好的了解我们自己的大脑功能？这些都需要更多学科的共同参与。在这方面影响较大的是Anthropic的mechanistic interpretability，领导这个项目的Chris Olah以前在Google和OpenAI都待过，所以我觉得OpenAI和Google或许也有一些相关的研究。

就写到这里，期待大家的批评指正。

01/28/2024
